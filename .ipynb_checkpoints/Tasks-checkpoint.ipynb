{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d91489b-2b80-4420-bf62-053a89358068",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa18f8a-05da-48b5-b8f0-9fb6d40ae6c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'S_Data/'\n",
    "endpoint = '.csv'\n",
    "\n",
    "csvs = ['customers', \n",
    "        'geolocation', \n",
    "        'order_items', \n",
    "        'order_payments', \n",
    "        'order_reviews', \n",
    "        'orders', \n",
    "        'product_category_name_translation',\n",
    "        'products',\n",
    "        'sellers']\n",
    "dfs = {}\n",
    "\n",
    "for name in csvs:\n",
    "    print(name.upper(),'\\n\\n')\n",
    "    dfs[name] = pd.read_csv(path+name+endpoint)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb02869-1c32-4722-98aa-d4130e379cb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f0014-3e35-419d-9ecb-667f4c46927a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### (done) english name, \n",
    "##### (done) average delivery time, \n",
    "##### (done) average delivery time from last 14 days,\n",
    "##### (done) average product price,\n",
    "##### (done) actual product price,\n",
    "##### (done) sales from last 14 days, \n",
    "##### (done) total sale per seller from 14 days, \n",
    "##### reviews since products sale started, \n",
    "##### number of reviews added in 14 days, \n",
    "##### average fracht_val in past 14 days\n",
    "##### get reviews in function same as other values in other df then merge dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535201-1b8a-4452-be09-d0236b0b2014",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3480c-50ce-4fcb-a9eb-f8ce4a9ecd9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. English name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2aef4bc-5d7a-4880-a556-593462e98448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>bebes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>37.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
       "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
       "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "3                 27.0                       261.0                 1.0   \n",
       "4                 37.0                       402.0                 4.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  \n",
       "3             371.0               26.0                4.0              26.0  \n",
       "4             625.0               20.0               17.0              13.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['products'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b04e8-8c38-44b2-b628-138e4325688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>bed_bath_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>furniture_decor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto\n",
       "3         cama_mesa_banho                bed_bath_table\n",
       "4        moveis_decoracao               furniture_decor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['product_category_name_translation'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a2f321-178d-4f27-895d-30d91400e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get english category name\n",
    "\n",
    "dfs['products'] = dfs['products'].merge(dfs['product_category_name_translation'],\n",
    "                                        how = 'inner',\n",
    "                                        on = 'product_category_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290205e-d68b-40fa-8c34-e264ecc5baae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Add missing delivery dates, get necessary date for subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daae76aa-382e-411f-9464-dbc20f777df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['orders'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08b6726-f7f2-4d7b-9ec4-c669107c9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['delivered', 'invoiced', 'shipped', 'processing', 'unavailable',\n",
       "       'canceled', 'created', 'approved'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['orders']['order_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c3032f-7d7d-4b6a-99e9-db4683cc36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get only valid orders\n",
    "dfs['orders'] = dfs['orders'].loc[(dfs['orders']['order_status'] != 'canceled') & \n",
    "                                  (dfs['orders']['order_status'] != 'unavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881e4e90-3dbf-4275-b722-a6530473d63e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                  19\n",
      "order_delivered_carrier_date      624\n",
      "order_delivered_customer_date    1737\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfs['orders'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd9fdce-65c0-4255-a32f-881a55bf7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object \n",
      " review_id                  object\n",
      "order_id                   object\n",
      "review_score                int64\n",
      "review_comment_title       object\n",
      "review_comment_message     object\n",
      "review_creation_date       object\n",
      "review_answer_timestamp    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfs['orders'].dtypes,\n",
    "      '\\n', \n",
    "      dfs['order_reviews'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11670e78-0c47-43fe-9f35-150b3716e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge dataframes for product id, price, number of ordered items, reviews\n",
    "dfs['orders'] = dfs['order_items'].merge(dfs['orders'], on = 'order_id', how = 'right')\n",
    "dfs['orders'] = dfs['orders'].merge(dfs['order_reviews'], on='order_id', how ='left')\n",
    "dfs['orders'] = dfs['orders'].merge(dfs['products'], on = 'product_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d89049f-2c70-48c4-96e6-204fbbf70cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/m_9l75x14kz_37vfj8r34b2r0000gn/T/ipykernel_17079/1906626660.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfs['orders']['order_delivered_customer_date'].ffill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dfs['orders']['order_purchase_timestamp'] = pd.to_datetime(dfs['orders']['order_purchase_timestamp'])\n",
    "dfs['orders']['order_delivered_customer_date'] = pd.to_datetime(dfs['orders']['order_delivered_customer_date'])\n",
    "dfs['orders']['review_creation_date'] = pd.to_datetime(dfs['orders']['review_creation_date'])\n",
    "\n",
    "## fill nan values after grouping by product id so values are more reliable\n",
    "dfs['orders'].sort_values(by='product_id', inplace=True)\n",
    "dfs['orders']['order_delivered_customer_date'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f020c555-1028-4bf7-b318-41aec7e6018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get order date, review date, delivery date and delivery time\n",
    "\n",
    "dfs['orders']['purchase_year'] = dfs['orders']['order_purchase_timestamp'].dt.year\n",
    "dfs['orders']['purchase_day'] = dfs['orders']['order_purchase_timestamp'].dt.dayofyear\n",
    "\n",
    "dfs['orders']['review_year'] = dfs['orders']['review_creation_date'].dt.year\n",
    "dfs['orders']['review_day'] = dfs['orders']['review_creation_date'].dt.dayofyear\n",
    "\n",
    "\n",
    "dfs['orders']['delivery_year'] = dfs['orders']['order_delivered_customer_date'].dt.year\n",
    "dfs['orders']['delivery_day'] = dfs['orders']['order_delivered_customer_date'].dt.dayofyear\n",
    "\n",
    "## calculate delivery time (check if delivery and purchase were made in same year)\n",
    "dfs['orders']['delivery_time'] = ((dfs['orders']['delivery_year'] - dfs['orders']['purchase_year'])*365 + \n",
    "                                 dfs['orders']['delivery_day'] - dfs['orders']['delivery_day'])\n",
    "\n",
    "## if delivery and purchase years were different check if purchase year was leap\n",
    "for index, row in dfs['orders'].iterrows():\n",
    "    if row['purchase_year'] != row['delivery_year']:\n",
    "        if row['purchase_year']%4 ==0 and row['purchase_year']%100 == 0 and row['purchase_year']%400 == 0:\n",
    "            dfs['orders'].at[index, 'delivery_time'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4fe5e-37b0-4e7a-afee-372fa8caecf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818ac581-e992-41ad-b6cf-1f91f5526f20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## get data from 14 days\n",
    "def is_leap(year):\n",
    "    if year%4 == 0 and year%100 == 0 and year%400 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522bea02-2019-4078-b5ac-ea419568d6d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## get end of subset (check if it ends in following year)\n",
    "def get_end(year, day_s, sub_size):\n",
    "    \n",
    "    if is_leap(year):\n",
    "        if day_s > 366 - sub_size:\n",
    "            day_e = 366 - day_s\n",
    "            year_e = year + 1\n",
    "        else:\n",
    "            day_e = day_s + sub_size\n",
    "            year_e = year\n",
    "    else:\n",
    "        if day_s > 365 - sub_size:\n",
    "            day_e = 365 - day_s\n",
    "            year_e = year + 1\n",
    "        else:\n",
    "            day_e = day_s + sub_size\n",
    "            year_e = year\n",
    "    return day_s, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60785e56-cb8c-4d95-ae5b-257b9491d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(dfs, day_end, year_end, column_gb):\n",
    "    \n",
    "    ## income from product per order\n",
    "    dfs['orders']['incomes'] = dfs['orders']['order_item_id']*dfs['orders']['price']\n",
    "\n",
    "    ## orders till end date\n",
    "    orders_bef = dfs['orders'].loc[(dfs['orders']['purchase_year'] < year_end) |\n",
    "                                   ((dfs['orders']['purchase_year'] == year_end) &\n",
    "                                    (dfs['orders']['purchase_day'] < day_end))]\n",
    "    ## df with orders before end day\n",
    "    df_bef = orders_bef.groupby(column_gb).agg({'delivery_time': 'mean', \n",
    "                                                'price': 'mean', \n",
    "                                                'order_item_id': 'sum', \n",
    "                                                'incomes': 'sum',\n",
    "                                                'freight_value': 'mean'}).reset_index()    \n",
    "    ## df with orders per seller before end day \n",
    "    df_bef_per_seller = orders_bef.groupby([column_gb, 'seller_id']).agg({'delivery_time': 'mean', \n",
    "                                                                          'price': 'mean', \n",
    "                                                                          'order_item_id': 'sum',\n",
    "                                                                          'incomes': 'sum',\n",
    "                                                                          'freight_value': 'mean'}).reset_index()\n",
    "    ## reviews since sale began\n",
    "    review_bef = dfs['orders'].loc[(dfs['orders']['review_year'] < year_end) |\n",
    "                                   ((dfs['orders']['review_year'] == year_end) &\n",
    "                                    (dfs['orders']['review_day'] < day_end))]\n",
    "    \n",
    "    ## df with mean reviews score for each product category since it sales began\n",
    "    df_bef_reviews = review_bef.groupby(column_gb)['review_score'].mean().reset_index()\n",
    "\n",
    "    ## merging dataframes to get proper information about product\n",
    "    df_before_start_day = df_bef.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_before_start_day.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "    \n",
    "    ## merging dataframes with collected informations for each seller\n",
    "    df_before_start_day_per_seller = df_bef_per_seller.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_before_start_day_per_seller.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "\n",
    "## at the end we have 2 dataframes: \n",
    "## 1st with product information since it sales began to start day\n",
    "## 2nd with product information same as in 1st one but for each seller\n",
    "    return(df_before_start_day, df_before_start_day_per_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8d3653-bcc4-4384-88f2-dc20b4c6b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_data(dfs, year, day_s, sub_size, column_gb):\n",
    "    \n",
    "    ##calculate end of subset\n",
    "    day_e, year_e = get_end(year, day_s, sub_size)\n",
    "\n",
    "    ## income from product per order\n",
    "    dfs['orders']['incomes'] = dfs['orders']['order_item_id']*dfs['orders']['price']\n",
    "    \n",
    "    ## orders from start date to end date\n",
    "    if year == year_e:\n",
    "        orders_act = dfs['orders'].loc[(dfs['orders']['purchase_year'] == year) & \n",
    "                                       (dfs['orders']['purchase_day'] >= day_s) & \n",
    "                                       (dfs['orders']['purchase_day'] <= day_e)]\n",
    "    else:\n",
    "        orders_act = dfs['orders'].loc[((dfs['orders']['purchase_year'] == year) & \n",
    "                                        (dfs['orders']['purchase_day'] >= day_s)) |\n",
    "                                       ((dfs['orders']['purchase_year'] == year_e) & \n",
    "                                        (dfs['orders']['purchase_day'] <= day_e))]\n",
    "                                        \n",
    "## each dataframe consists \n",
    "##    mean values: delivery time, price and freight value\n",
    "##    sum values: incomes and number of ordered items\n",
    "\n",
    "    ## df with orders from start date to end date\n",
    "    df_act = orders_act.groupby(column_gb).agg({'delivery_time': 'mean', \n",
    "                                                   'price': 'mean', \n",
    "                                                   'order_item_id': 'sum', \n",
    "                                                   'incomes': 'sum',\n",
    "                                                   'freight_value': 'mean'}).reset_index()\n",
    "                                \n",
    "## same information collected for each seller\n",
    "\n",
    "    ## df with orders from start date to end date\n",
    "    df_act_per_seller = orders_act.groupby([column_gb, 'seller_id']).agg({'delivery_time': 'mean', \n",
    "                                                                             'price': 'mean', \n",
    "                                                                             'order_item_id': 'sum',\n",
    "                                                                             'incomes': 'sum',\n",
    "                                                                             'freight_value': 'mean'}).reset_index()\n",
    "\n",
    "    ## reviews added between start and end date \n",
    "    if year == year_e:\n",
    "        review_act = dfs['orders'].loc[(dfs['orders']['review_year'] == year) & \n",
    "                                       (dfs['orders']['review_day'] >= day_s) & \n",
    "                                       (dfs['orders']['review_day'] <= day_e)]\n",
    "    else:\n",
    "        review_act = dfs['orders'].loc[((dfs['orders']['review_year'] == year) & \n",
    "                                        (dfs['orders']['review_day'] >= day_s)) |\n",
    "                                       ((dfs['orders']['review_year'] == year_e) & \n",
    "                                        (dfs['orders']['review_day'] <= day_e))]\n",
    "\n",
    "    ## df with mean reviews score value in time period from start to end date for each product \n",
    "    df_act_reviews = review_act.groupby(column_gb)['review_score'].mean().reset_index()\n",
    "\n",
    "## merging dataframes to get proper information about product\n",
    "    df_actual = df_act.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_actual.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                              'price': 'avg_price',\n",
    "                              'order_item_id' : 'number_of_sold_items',\n",
    "                              'freight_value': 'avg_freight_val',\n",
    "                              'review_score': 'avg_review_score'},\n",
    "                     inplace = True)                     \n",
    "\n",
    "## merging dataframes with collected informations for each seller\n",
    "    df_actual_per_seller = df_act_per_seller.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_actual_per_seller.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "\n",
    "## at the end we have 2 dataframes: \n",
    "## 1st with product information from start date to end date\n",
    "## 2nd with product information same as in 1st one but for each seller\n",
    "    return(df_actual, df_actual_per_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e4de-733b-4752-9627-b60e9f912322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate period of time for historical data\n",
    "def period(day, year, year_start, day_start):\n",
    "    if year == year_start:\n",
    "        return day - day_start\n",
    "    elif year - year_start == 1:\n",
    "        if is_leap(year_start):\n",
    "            return day + 366 - day_start\n",
    "        else:\n",
    "            return day + 365 - day_start\n",
    "    else:\n",
    "        if is_leap(year_start):\n",
    "            days = 366 - day_start\n",
    "        else:\n",
    "            days = 365 - day_start\n",
    "        for i in range(year-year_start-1):\n",
    "            if is_leap(year_start+i+1):\n",
    "                days+=366\n",
    "            else:\n",
    "                days+=365\n",
    "        return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb061a-30a4-421b-a0b3-e144a6cbd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates_subset(df, day_s, year_s, sub_size):\n",
    "    day_e, year_e = get_end(year, day_s, sub_size)\n",
    "    df['start_day'] = day_start\n",
    "    df['start_year'] = year_start\n",
    "    df['time_period'] = sub_size\n",
    "    df['end_day'] = day_e\n",
    "    df['end_year'] = year_e\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b7916-97fc-4f23-a482-a8218515650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates_historical(df, day_start, year_start, day_end, year_end):\n",
    "    df['start_day'] = day_start\n",
    "    df['start_year'] = year_start\n",
    "    df['time_period'] = period(day_end, year_end)\n",
    "    df['end_day'] = day_end\n",
    "    df['end_year'] = year_end\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb0d374-cb6f-4d43-ae0a-003d95266bdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [product_category, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  product_category  avg_delivery_time   avg_price  \\\n",
       " 0                 air_conditioning         146.000000  170.709000   \n",
       " 1                            audio           0.000000   78.495000   \n",
       " 2                             auto          81.111111  156.472222   \n",
       " 3                             baby           0.000000  124.651818   \n",
       " 4                   bed_bath_table           0.000000   59.873750   \n",
       " 5           books_general_interest         365.000000  119.500000   \n",
       " 6                  books_technical         365.000000  267.000000   \n",
       " 7            computers_accessories         191.190476   66.634286   \n",
       " 8                   consoles_games          73.000000  388.226000   \n",
       " 9                       cool_stuff           0.000000  149.442857   \n",
       " 10             diapers_and_hygiene           0.000000  134.900000   \n",
       " 11                     electronics           0.000000  107.990000   \n",
       " 12          fashio_female_clothing           0.000000   54.900000   \n",
       " 13        fashion_bags_accessories           0.000000   46.662500   \n",
       " 14           fashion_male_clothing           0.000000   24.900000   \n",
       " 15                   fashion_shoes           0.000000   29.990000   \n",
       " 16                 fixed_telephony           0.000000  140.976000   \n",
       " 17                            food           0.000000   79.900000   \n",
       " 18                 furniture_decor          29.594595   86.587297   \n",
       " 19                    garden_tools           0.000000  271.976000   \n",
       " 20                   health_beauty          44.693878   92.848776   \n",
       " 21                      housewares           0.000000  107.255833   \n",
       " 22  industry_commerce_and_business           0.000000   89.900000   \n",
       " 23                    market_place         112.307692  100.476154   \n",
       " 24                office_furniture           0.000000  216.813333   \n",
       " 25                       perfumery           0.000000  166.520690   \n",
       " 26                        pet_shop           0.000000  172.420000   \n",
       " 27                  sports_leisure           0.000000  118.361765   \n",
       " 28                       telephony          40.555556   28.908889   \n",
       " 29                            toys           0.000000  171.104167   \n",
       " 30                   watches_gifts         146.000000  672.048000   \n",
       " \n",
       "     number_of_sold_items  incomes  avg_freight_val  avg_review_score  \n",
       " 0                   18.0  2935.29        19.782000          3.800000  \n",
       " 1                    2.0   156.99        13.020000          5.000000  \n",
       " 2                    9.0  1408.25        38.245556          2.857143  \n",
       " 3                   13.0  1510.97        13.307273          4.090909  \n",
       " 4                   16.0   757.77        15.948750          3.375000  \n",
       " 5                    1.0   119.50        25.040000               NaN  \n",
       " 6                    1.0   267.00        32.840000          1.000000  \n",
       " 7                   27.0  1627.32        16.227143          2.761905  \n",
       " 8                   10.0  3882.26        20.716000          3.400000  \n",
       " 9                    7.0  1046.10        27.254286          4.142857  \n",
       " 10                   1.0   134.90        16.090000          5.000000  \n",
       " 11                   1.0   107.99        11.800000          5.000000  \n",
       " 12                   1.0    54.90        14.730000          5.000000  \n",
       " 13                   9.0   398.20        16.210000          3.500000  \n",
       " 14                   1.0    24.90        10.960000          1.000000  \n",
       " 15                   1.0    29.99        10.960000          5.000000  \n",
       " 16                   5.0   704.88        13.914000          4.000000  \n",
       " 17                   1.0    79.90        16.330000          5.000000  \n",
       " 18                 112.0  7983.64        18.675000          3.575342  \n",
       " 19                   5.0  1359.88        21.062000          4.200000  \n",
       " 20                  56.0  4914.25        18.424694          3.208333  \n",
       " 21                  16.0  1816.67        21.289167          3.083333  \n",
       " 22                   5.0   449.50        18.490000          4.250000  \n",
       " 23                  29.0  2652.59        20.999231          4.538462  \n",
       " 24                   6.0  1300.88        47.778333          1.600000  \n",
       " 25                  33.0  5213.70        16.762069          4.310345  \n",
       " 26                   4.0   689.68        21.545000          4.250000  \n",
       " 27                  17.0  2012.15        28.153529          4.250000  \n",
       " 28                  10.0   300.08        13.512222          4.111111  \n",
       " 29                  26.0  4421.39        20.209583          3.666667  \n",
       " 30                   5.0  3360.24        21.560000          4.750000  ,\n",
       " Empty DataFrame\n",
       " Columns: [product_category, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
       " Index: [],\n",
       "      product_category                         seller_id  avg_delivery_time  \\\n",
       " 0    air_conditioning  c7dcd301ecfe5ab7f778ac172cf74be7           0.000000   \n",
       " 1    air_conditioning  ed859002ad59dbf8cf3602696a6c3000         162.222222   \n",
       " 2               audio  5f0057b677eb963672bf05dfa3f16c34           0.000000   \n",
       " 3                auto  63b9ae557efed31d1f7687917d248a8d           0.000000   \n",
       " 4                auto  6cf476a4ca74498db55cbccdaa9dcfb6           0.000000   \n",
       " ..                ...                               ...                ...   \n",
       " 161              toys  f5f2ab9bdb6b30c14c61be68c5ed37da           0.000000   \n",
       " 162              toys  fa40cc5b934574b62717c68f3d678b6d           0.000000   \n",
       " 163     watches_gifts  4d600e08ecbe08258c79e536c5a42fee         243.333333   \n",
       " 164     watches_gifts  522620dcb18a6b31cd7bdf73665113a9           0.000000   \n",
       " 165     watches_gifts  7e93a43ef30c4f03f38b393420bc753a           0.000000   \n",
       " \n",
       "        avg_price  number_of_sold_items  incomes  avg_freight_val  \\\n",
       " 0     299.990000                   1.0   299.99        19.010000   \n",
       " 1     156.344444                  17.0  2635.30        19.867778   \n",
       " 2      78.495000                   2.0   156.99        13.020000   \n",
       " 3      10.000000                   1.0    10.00        14.520000   \n",
       " 4     499.990000                   1.0   499.99        94.470000   \n",
       " ..           ...                   ...      ...              ...   \n",
       " 161    71.945000                   2.0   143.89        20.185000   \n",
       " 162    49.900000                   1.0    49.90        24.840000   \n",
       " 163   643.780000                   3.0  1931.34        22.563333   \n",
       " 164    29.900000                   1.0    29.90        15.560000   \n",
       " 165  1399.000000                   1.0  1399.00        24.550000   \n",
       " \n",
       "      avg_review_score  \n",
       " 0            3.800000  \n",
       " 1            3.800000  \n",
       " 2            5.000000  \n",
       " 3            2.857143  \n",
       " 4            2.857143  \n",
       " ..                ...  \n",
       " 161          3.666667  \n",
       " 162          3.666667  \n",
       " 163          4.750000  \n",
       " 164          4.750000  \n",
       " 165          4.750000  \n",
       " \n",
       " [166 rows x 8 columns],\n",
       " Empty DataFrame\n",
       " Columns: [product_category, seller_id, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
       " Index: [])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_14(dfs, year_start, day_start+100, subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73562ffb-518e-482c-8ec4-a7bf6e9bffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "year_start = dfs['orders'].sort_values(by='purchase_year')['purchase_year'].values[0]\n",
    "day_start =  dfs['orders'].sort_values(by=['purchase_year', 'purchase_day'])['purchase_day'].values[0]\n",
    "\n",
    "year_end =  dfs['orders'].sort_values(by='purchase_year', ascending = False)['purchase_year'].values[0]\n",
    "day_end =  dfs['orders'].sort_values(by=['purchase_year', 'purchase_day'], \n",
    "                                     ascending = [False, False])['purchase_day'].values[0]\n",
    "if day_end >= 7:\n",
    "    day_end -= 7\n",
    "else:\n",
    "    year_end -= 1\n",
    "    day_end = 365 + day_end - 7\n",
    "    if is_leap(year_end):\n",
    "        day_end += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "offset = 0 # after how many subset collected  you want to start collecting historical data (from start day there wont be much data)\n",
    "subset_size = 14\n",
    "loop = 0\n",
    "start = True\n",
    "is_product_new = False\n",
    "\n",
    "\n",
    "if is_product_new:\n",
    "    column_groupby = 'product_id'\n",
    "else:\n",
    "    column_groupby = 'product_category_name_english'\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data_per_seller = pd.DataFrame()\n",
    "\n",
    "## go through all years and days, start parameter let start from proper day\n",
    "for year in range(year_start, year_end +1):\n",
    "    for day in range(0, 365):\n",
    "        loop += 1\n",
    "        if start:\n",
    "            day = day_start\n",
    "            start = False\n",
    "            pass\n",
    "        else:\n",
    "            if (day >= day_end)&(year>=year_end):\n",
    "                break\n",
    "            else:\n",
    "                actual, actual_per_seller = get_subset_data(dfs, year, day, subset_size, columns_groupby)\n",
    "                actual = add_dates_subset(actual, day_start, year_start, subset_size)\n",
    "                actual_per_seller = add_dates_subset(before_per_seller, day_start, year_start, subset_size)\n",
    "                if loop == 1:\n",
    "                    data = actual\n",
    "                    data_per_seller = actual_per_seller\n",
    "                else:\n",
    "                    data = pd.concat([data, actual], ignore_index=True)\n",
    "                    data_per_seller = pd.concat([data_per_seller, actual_per_seller], ignore_index=True)\n",
    "                day = day + subset_size\n",
    "                \n",
    "historical, historical_per_seller =  get_historical_data(dfs, day_end, year_end, columns_groupby)\n",
    "historical = add_dates_historical(historical, day_start, year_start, day_end, year_end)\n",
    "historical_per_seller = add_dates_historical(historical_per_seller, day_start, year_start, day_end, year_end)\n",
    "data = pd.concat([data, historical], ignore_index=True)\n",
    "data_per_seller = pd.concat([data_per_seller, historical_per_seller], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa362c-e2b1-400e-ae0c-4b842e6925cd",
   "metadata": {},
   "source": [
    "### TIME FOR TRAIN AND TEST \n",
    "### ALSO CHECK IF NEW PRODUCT IF YES FIND SIMILIAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040fe4f-97f9-49e3-b5a3-e810b70a05b7",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "372839c8-40bc-4137-8d6b-7398949f5248",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMERS\n",
      "GEOLOCATION\n",
      "ORDER_ITEMS\n",
      "ORDER_PAYMENTS\n",
      "ORDER_REVIEWS\n",
      "ORDERS\n",
      "PRODUCT_CATEGORY_NAME_TRANSLATION\n",
      "PRODUCTS\n",
      "SELLERS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = 'S_Data/'\n",
    "endpoint = '.csv'\n",
    "\n",
    "csvs = ['customers', \n",
    "        'geolocation', \n",
    "        'order_items', \n",
    "        'order_payments', \n",
    "        'order_reviews', \n",
    "        'orders', \n",
    "        'product_category_name_translation',\n",
    "        'products',\n",
    "        'sellers']\n",
    "dfs = {}\n",
    "\n",
    "for name in csvs:\n",
    "    print(name.upper())\n",
    "    dfs[name] = pd.read_csv(path+name+endpoint)\n",
    "\n",
    "dfs['orders']['order_purchase_timestamp'] = pd.to_datetime(dfs['orders']['order_purchase_timestamp'])\n",
    "# get english category name\n",
    "dfs['products'] = dfs['products'].merge(dfs['product_category_name_translation'],\n",
    "                                        how = 'inner',\n",
    "                                        on = 'product_category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7239c8e6-2cad-4841-af26-014b47350a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function filters data by date if necessary\n",
    "def get_turnover(df, start_day, start_month, start_year, end_day, end_month, end_year):\n",
    "    \n",
    "    start_date = pd.Timestamp(year=start_year, month=start_month, day=start_day)\n",
    "    end_date = pd.Timestamp(year=end_year, month=end_month, day=end_day)\n",
    "    \n",
    "    df_filtered = df[df['order_purchase_timestamp'].between(start_date, end_date)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ada7f0-d33d-4d7c-b04f-78e40c40f5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. the sellers with the biggest/smallest turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec4528-8197-4438-baef-9ed76d6e3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# select how many top sellers you want to see\n",
    "top = 10\n",
    "\n",
    "## select time period for turnover per seller\n",
    "## if year parameters are 0 whole data frame will be used\n",
    "start_day = 1\n",
    "start_month = 1\n",
    "start_year = 0\n",
    "end_day = 1\n",
    "end_month = 1\n",
    "end_year = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2478e88-a022-4cae-a218-961c894710fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 sellers with biggest turnover: \n",
      "                           seller_id  total_amount  seller_zip_code_prefix  \\\n",
      "0  cf6f6bc4df3999b9c6440f124fb2f687         12.22                    4937   \n",
      "1  77128dec4bec4878c37ab7d6169d6f26         15.22                    2610   \n",
      "2  4965a7002cca77301c82d3f91b82e1a9         16.36                   18074   \n",
      "3  702835e4b785b67a084280efca355756         18.56                   36046   \n",
      "4  ad14615bdd492b01b0d97922e87cb87f         19.21                   88704   \n",
      "5  3ac588cd562971392504a9e17130c40b         19.29                   13480   \n",
      "6  c1dde11f12d05c478f5de2d7319ad3b2         19.89                    1026   \n",
      "7  cc1f04647be106ba74e62b21f358af25         20.19                    2739   \n",
      "8  b5f0712d22a873b6797ab6cc65c3fcba         21.28                    2316   \n",
      "9  34aefe746cd81b7f3b23253ea28bef39         22.52                   81210   \n",
      "\n",
      "    seller_city seller_state  \n",
      "0     sao paulo           SP  \n",
      "1     sao paulo           SP  \n",
      "2      sorocaba           SP  \n",
      "3  juiz de fora           MG  \n",
      "4       tubarao           SC  \n",
      "5       limeira           SP  \n",
      "6     sao paulo           SP  \n",
      "7     sao paulo           SP  \n",
      "8     sao paulo           SP  \n",
      "9      curitiba           PR   \n",
      "\n",
      "top 10 sellers with smallest turnover: \n",
      "                              seller_id  total_amount  seller_zip_code_prefix  \\\n",
      "3085  7e93a43ef30c4f03f38b393420bc753a     184320.77                    6429   \n",
      "3086  955fee9216a65b617aa5c0531780ce60     198078.49                    4782   \n",
      "3087  fa1c13f2614d7b5c4749cbc52fecda94     205775.24                   13170   \n",
      "3088  1f50f920176fa81dab994f9023523100     214499.35                   15025   \n",
      "3089  da8622b14eb17ae2831f4ac5b9dab84a     228418.57                   13405   \n",
      "3090  1025f0e2d44d7041d6cf58b6550e0bfa     240516.24                    3204   \n",
      "3091  4869f7a5dfa277a7dca6462dcf3b52b2     256418.18                   14840   \n",
      "3092  53243585a1d6dc2643021fd1853d8905     260379.81                   42738   \n",
      "3093  4a3ca9315b744ce9f8e9374361493884     266660.94                   14940   \n",
      "3094  7c67e1448b00f6e969d365cea6b010ab     375389.31                    8577   \n",
      "\n",
      "                seller_city seller_state  \n",
      "3085                barueri           SP  \n",
      "3086              sao paulo           SP  \n",
      "3087                 sumare           SP  \n",
      "3088  sao jose do rio preto           SP  \n",
      "3089             piracicaba           SP  \n",
      "3090              sao paulo           SP  \n",
      "3091                guariba           SP  \n",
      "3092       lauro de freitas           BA  \n",
      "3093               ibitinga           SP  \n",
      "3094        itaquaquecetuba           SP  \n"
     ]
    }
   ],
   "source": [
    "turnover = dfs['orders'].merge(dfs['order_items'], on = 'order_id', how = 'left')\n",
    "\n",
    "# get amount for each order\n",
    "turnover['total_amount'] = turnover['order_item_id']*turnover['price'] + turnover['order_item_id']*turnover['freight_value']\n",
    "\n",
    "if start_year !=0 and end_year !=0:\n",
    "    turnover_df = get_turnover(turnover, start_day, start_month, start_year, end_day, end_month, end_year)\n",
    "else:\n",
    "    turnover_df = turnover\n",
    "\n",
    "# get total incomes per seller\n",
    "turnover_per_seller = turnover_df.groupby('seller_id')['total_amount'].sum().reset_index().sort_values(by='total_amount')\n",
    "turnover_per_seller = turnover_per_seller.merge(dfs['sellers'], on = 'seller_id', how = 'left')  \n",
    "\n",
    "if top < turnover_per_seller.size:\n",
    "    print(f'top {top} sellers with biggest turnover: \\n', turnover_per_seller.head(top), '\\n')\n",
    "    print(f'top {top} sellers with smallest turnover: \\n', turnover_per_seller.tail(top))\n",
    "else:\n",
    "    print('sellers turnover: \\n', turnover_per_seller)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b048b-9269-409d-9b05-33eba927e18d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. leaders/outsiders in sales in each area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c63bf1dd-105a-45aa-ab03-ec93e144f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# select how many top sellers you want to see\n",
    "top = 3\n",
    "\n",
    "## select time period for turnover per seller\n",
    "## if year parameters are 0 whole data frame will be used\n",
    "start_day = 1\n",
    "start_month = 1\n",
    "start_year = 0\n",
    "end_day = 1\n",
    "end_month = 1\n",
    "end_year = 0\n",
    "\n",
    "# select categories you want to see leaders and outsiders in\n",
    "# you can select one category as string or many as list\n",
    "# if other type will be provided you will see leaders and outsiders for all categories\n",
    "category = ['art', 'auto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "93cc0c1f-472d-4a2c-8ba7-38dd5bfcc9ac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agro_industry_and_commerce\n",
      "air_conditioning\n",
      "art\n",
      "arts_and_craftmanship\n",
      "audio\n",
      "auto\n",
      "baby\n",
      "bed_bath_table\n",
      "books_general_interest\n",
      "books_imported\n",
      "books_technical\n",
      "cds_dvds_musicals\n",
      "christmas_supplies\n",
      "cine_photo\n",
      "computers\n",
      "computers_accessories\n",
      "consoles_games\n",
      "construction_tools_construction\n",
      "construction_tools_lights\n",
      "construction_tools_safety\n",
      "cool_stuff\n",
      "costruction_tools_garden\n",
      "costruction_tools_tools\n",
      "diapers_and_hygiene\n",
      "drinks\n",
      "dvds_blu_ray\n",
      "electronics\n",
      "fashio_female_clothing\n",
      "fashion_bags_accessories\n",
      "fashion_childrens_clothes\n",
      "fashion_male_clothing\n",
      "fashion_shoes\n",
      "fashion_sport\n",
      "fashion_underwear_beach\n",
      "fixed_telephony\n",
      "flowers\n",
      "food\n",
      "food_drink\n",
      "furniture_bedroom\n",
      "furniture_decor\n",
      "furniture_living_room\n",
      "furniture_mattress_and_upholstery\n",
      "garden_tools\n",
      "health_beauty\n",
      "home_appliances\n",
      "home_appliances_2\n",
      "home_comfort_2\n",
      "home_confort\n",
      "home_construction\n",
      "housewares\n",
      "industry_commerce_and_business\n",
      "kitchen_dining_laundry_garden_furniture\n",
      "la_cuisine\n",
      "luggage_accessories\n",
      "market_place\n",
      "music\n",
      "musical_instruments\n",
      "nan\n",
      "office_furniture\n",
      "party_supplies\n",
      "perfumery\n",
      "pet_shop\n",
      "security_and_services\n",
      "signaling_and_security\n",
      "small_appliances\n",
      "small_appliances_home_oven_and_coffee\n",
      "sports_leisure\n",
      "stationery\n",
      "tablets_printing_image\n",
      "telephony\n",
      "toys\n",
      "watches_gifts\n"
     ]
    }
   ],
   "source": [
    "all_categories = sales_areas_df['product_category_name_english'].unique()\n",
    "all_categories = all_categories.astype(str)\n",
    "all_categories = np.sort(all_categories)\n",
    "for el in all_categories:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e37b789d-ded7-4801-9090-c4cee5062f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_areas = dfs['orders'].merge(dfs['order_items'], on = 'order_id', how = 'left')\n",
    "sales_areas = sales_areas.merge(dfs['products'], on = 'product_id', how = 'left')\n",
    "\n",
    "if start_year !=0 and end_year !=0:\n",
    "    sales_areas_df = get_turnover(sales_areas, start_day, start_month, start_year, end_day, end_month, end_year)\n",
    "else:\n",
    "    sales_areas_df = sales_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e452b99c-2b92-4b7d-821a-39a5bfa7e3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(data, category_name, top):\n",
    "    if top < data.size:\n",
    "        print(f'top {top} leaders with biggest turnover in category {category_name}: \\n', data.head(top), '\\n')\n",
    "        print(f'top {top} outsiders with smallest turnover in category {category_name}: \\n', data.tail(top))\n",
    "        # possible to print every seller that sold the same amount of item if number of such sellers is bigger than top parameter\n",
    "    else:\n",
    "        print(f'sellers turnover in category {category_name}: \\n', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "03138cfd-b3e1-474b-bfad-863255969706",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 leaders with biggest turnover in category art: \n",
      "     product_category_name_english                         seller_id  \\\n",
      "116                           art  c31eff8334d6b3047ed34bebd4d62c36   \n",
      "109                           art  a0e19590a0923cdd0614ea9427713ced   \n",
      "107                           art  955fee9216a65b617aa5c0531780ce60   \n",
      "\n",
      "     order_item_id  seller_zip_code_prefix           seller_city seller_state  \n",
      "116          111.0                   13322                 salto           SP  \n",
      "109           22.0                   83075  sao jose dos pinhais           PR  \n",
      "107           11.0                    4782             sao paulo           SP   \n",
      "\n",
      "top 3 outsiders with smallest turnover in category art: \n",
      "     product_category_name_english                         seller_id  \\\n",
      "90                            art  0f94588695d71662beec8d883ffacf09   \n",
      "89                            art  0ddefe3c7a032b91f4e25b9c3a08fca1   \n",
      "121                           art  f593898ec748b7a8cb81fc04edafd98a   \n",
      "\n",
      "     order_item_id  seller_zip_code_prefix            seller_city seller_state  \n",
      "90             1.0                   88037          florianopolis           SC  \n",
      "89             1.0                    9721  sao bernardo do campo           SP  \n",
      "121            1.0                   13920               pedreira           SP  \n",
      "\n",
      "\n",
      "top 3 leaders with biggest turnover in category auto: \n",
      "     product_category_name_english                         seller_id  \\\n",
      "376                          auto  8581055ce74af1daba164fdbd55a40de   \n",
      "204                          auto  16090f2ca825584b5a147ab24aa30c86   \n",
      "344                          auto  7142540dd4c91e2237acb7e911c4eba2   \n",
      "\n",
      "     order_item_id  seller_zip_code_prefix seller_city seller_state  \n",
      "376          489.0                    7112   guarulhos           SP  \n",
      "204          259.0                   12940     atibaia           SP  \n",
      "344          232.0                   16301   penapolis           SP   \n",
      "\n",
      "top 3 outsiders with smallest turnover in category auto: \n",
      "     product_category_name_english                         seller_id  \\\n",
      "440                          auto  b0398568231ba5e6734af1881671a317   \n",
      "277                          auto  455c5640e8c5bd1b2ee85c0158f85727   \n",
      "362                          auto  7c1fea10b5b006671d608b1d7c446ec4   \n",
      "\n",
      "     order_item_id  seller_zip_code_prefix seller_city seller_state  \n",
      "440            1.0                   29704    colatina           ES  \n",
      "277            1.0                   89128  luiz alves           SC  \n",
      "362            1.0                   18550     boituva           SP  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "turnover_per_category_seller = sales_areas_df.groupby(['product_category_name_english', 'seller_id'])['order_item_id'].sum().reset_index()\n",
    "turnover_per_category_seller = turnover_per_category_seller.merge(dfs['sellers'], on = 'seller_id', how = 'left')  \n",
    "\n",
    "if isinstance(category, list):\n",
    "    for el in category:\n",
    "        category_data = turnover_per_category_seller.loc[turnover_per_category_seller['product_category_name_english'] == el].sort_values(by='order_item_id', ascending= False)\n",
    "        print_data(category_data, el, top)\n",
    "        print('\\n')\n",
    "elif isinstance(category, str):\n",
    "    category_data = turnover_per_category_seller.loc[turnover_per_category_seller['product_category_name_english'] == category].sort_values(by='order_item_id', ascending= False)\n",
    "    print_data(category_data, category, top)\n",
    "\n",
    "else:\n",
    "    for el in all_categories:\n",
    "        category_data = turnover_per_category_seller.loc[turnover_per_category_seller['product_category_name_english'] == el].sort_values(by='order_item_id', ascending= False)\n",
    "        print_data(category_data, el, top)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a600cef6-0833-41a2-aa15-15392b7396c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3. which products sell best in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7ab8e9a7-bd87-4b61-b56e-8e1a81df400d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agro_industry_and_commerce\n",
      "air_conditioning\n",
      "art\n",
      "arts_and_craftmanship\n",
      "audio\n",
      "auto\n",
      "baby\n",
      "bed_bath_table\n",
      "books_general_interest\n",
      "books_imported\n",
      "books_technical\n",
      "cds_dvds_musicals\n",
      "christmas_supplies\n",
      "cine_photo\n",
      "computers\n",
      "computers_accessories\n",
      "consoles_games\n",
      "construction_tools_construction\n",
      "construction_tools_lights\n",
      "construction_tools_safety\n",
      "cool_stuff\n",
      "costruction_tools_garden\n",
      "costruction_tools_tools\n",
      "diapers_and_hygiene\n",
      "drinks\n",
      "dvds_blu_ray\n",
      "electronics\n",
      "fashio_female_clothing\n",
      "fashion_bags_accessories\n",
      "fashion_childrens_clothes\n",
      "fashion_male_clothing\n",
      "fashion_shoes\n",
      "fashion_sport\n",
      "fashion_underwear_beach\n",
      "fixed_telephony\n",
      "flowers\n",
      "food\n",
      "food_drink\n",
      "furniture_bedroom\n",
      "furniture_decor\n",
      "furniture_living_room\n",
      "furniture_mattress_and_upholstery\n",
      "garden_tools\n",
      "health_beauty\n",
      "home_appliances\n",
      "home_appliances_2\n",
      "home_comfort_2\n",
      "home_confort\n",
      "home_construction\n",
      "housewares\n",
      "industry_commerce_and_business\n",
      "kitchen_dining_laundry_garden_furniture\n",
      "la_cuisine\n",
      "luggage_accessories\n",
      "market_place\n",
      "music\n",
      "musical_instruments\n",
      "nan\n",
      "office_furniture\n",
      "party_supplies\n",
      "perfumery\n",
      "pet_shop\n",
      "security_and_services\n",
      "signaling_and_security\n",
      "small_appliances\n",
      "small_appliances_home_oven_and_coffee\n",
      "sports_leisure\n",
      "stationery\n",
      "tablets_printing_image\n",
      "telephony\n",
      "toys\n",
      "watches_gifts\n"
     ]
    }
   ],
   "source": [
    "all_categories = sales_areas_df['product_category_name_english'].unique()\n",
    "all_categories = all_categories.astype(str)\n",
    "all_categories = np.sort(all_categories)\n",
    "for el in all_categories:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2d7890eb-7414-498a-88e8-5e6705b32e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "## select time period for products sale\n",
    "## if year parameters are 0 whole data frame will be used\n",
    "start_day = 1\n",
    "start_month = 1\n",
    "start_year = 0\n",
    "end_day = 1\n",
    "end_month = 1\n",
    "end_year = 0\n",
    "\n",
    "# select categories you want to see best products in\n",
    "# you can select one category as a string or many as a list\n",
    "# if other type will be provided you will see leaders and outsiders for all categories\n",
    "category = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9a747989-2125-48f3-a650-be09b24d6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data(data, category):\n",
    "    if len(data) > 0:\n",
    "        sold = round(data.sort_values(by='sold_items', ascending=False)['sold_items'].values[0], 0)\n",
    "        data = data.loc[data['sold_items'] == sold]\n",
    "        \n",
    "        if len(data) > 1:\n",
    "            print(f'best-selling products in category {category} (sold {sold}): \\n', data['product_id'].values)\n",
    "            # possible to print every seller that sold the same amount of item if number of such sellers is bigger than top parameter\n",
    "        else:\n",
    "            print(f'best-selling product in category {category} (sold {sold}): \\n', data['product_id'].values)\n",
    "    else:\n",
    "        print(f'no product sold in category {category}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6490dba0-a4ac-4c3c-9295-d81f97dbdbab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best-selling product in category agro_industry_and_commerce (sold 23.0): \n",
      " ['11250b0d4b709fee92441c5f34122aed']\n",
      "best-selling product in category air_conditioning (sold 30.0): \n",
      " ['f2a1b32f85cad59ff2a8444154ac25f0']\n",
      "best-selling product in category art (sold 111.0): \n",
      " ['4fe644d766c7566dbc46fb851363cb3b']\n",
      "best-selling product in category arts_and_craftmanship (sold 5.0): \n",
      " ['b9976e9c22fb1540bd71d1bcd2989475']\n",
      "best-selling product in category audio (sold 49.0): \n",
      " ['db5efde3ad0cc579b130d71c4b2db522']\n",
      "best-selling product in category auto (sold 210.0): \n",
      " ['9571759451b1d780ee7c15012ea109d4']\n",
      "best-selling product in category baby (sold 95.0): \n",
      " ['cac9e5692471a0700418aa3400b9b2b1']\n",
      "best-selling product in category bed_bath_table (sold 542.0): \n",
      " ['99a4788cb24856965c36a24e339b6058']\n",
      "best-selling product in category books_general_interest (sold 61.0): \n",
      " ['f35927953ed82e19d06ad3aac2f06353']\n",
      "best-selling product in category books_imported (sold 9.0): \n",
      " ['68ad45d48d69404aeb71ce87e1b2c948']\n",
      "best-selling product in category books_technical (sold 44.0): \n",
      " ['173e9fe34bfe97f3a5e6dc57fe897b74']\n",
      "best-selling product in category cds_dvds_musicals (sold 16.0): \n",
      " ['1dceebcc5f23c02ea23e16d5bedca000']\n",
      "best-selling product in category christmas_supplies (sold 24.0): \n",
      " ['f3ccdb9f9c7f31e0efd626e9110b85f5']\n",
      "best-selling product in category cine_photo (sold 13.0): \n",
      " ['e988092a8afe5d9393a5c3a7ca17691c']\n",
      "best-selling product in category computers (sold 35.0): \n",
      " ['d6160fb7873f184099d9bc95e30376af']\n",
      "best-selling product in category computers_accessories (sold 369.0): \n",
      " ['d1c427060a0f73f6b889a5c7c61f2ac4']\n",
      "best-selling product in category consoles_games (sold 154.0): \n",
      " ['0aabfb375647d9738ad0f7b4ea3653b1']\n",
      "best-selling product in category construction_tools_construction (sold 46.0): \n",
      " ['7564c1759c04fc0a38f2aa84f7a370ee']\n",
      "best-selling product in category construction_tools_lights (sold 69.0): \n",
      " ['216bb0e0cd43ffd832e0973d35e0377e']\n",
      "best-selling products in category construction_tools_safety (sold 29.0): \n",
      " ['56c221c4c1a4a98293895c4563cdc6bf' '82c51c3938503a4ddc096fbed86428d6']\n",
      "best-selling product in category cool_stuff (sold 122.0): \n",
      " ['601a360bd2a916ecef0e88de72a6531a']\n",
      "best-selling product in category costruction_tools_garden (sold 24.0): \n",
      " ['71a7800a633691de8ecdd17463335e2e']\n",
      "best-selling product in category costruction_tools_tools (sold 18.0): \n",
      " ['5e53af05c040b01584b81b3549945faf']\n",
      "best-selling product in category diapers_and_hygiene (sold 40.0): \n",
      " ['3fdb534dccf5bc9ab0406944b913787d']\n",
      "best-selling product in category drinks (sold 104.0): \n",
      " ['cd48f265a63e13b762601f5f794c5fca']\n",
      "best-selling product in category dvds_blu_ray (sold 7.0): \n",
      " ['d55d2479e56093f23ebcf313ceb3bcfe']\n",
      "best-selling product in category electronics (sold 108.0): \n",
      " ['7ce94ab189134e2d3c05f496d635419c']\n",
      "best-selling product in category fashio_female_clothing (sold 18.0): \n",
      " ['63cf4d771cba1d380af927afe5895d4b']\n",
      "best-selling product in category fashion_bags_accessories (sold 144.0): \n",
      " ['d017a2151d543a9885604dc62a3d9dcc']\n",
      "best-selling product in category fashion_childrens_clothes (sold 3.0): \n",
      " ['57bdf3098169cccdb62221bd3e089cbd']\n",
      "best-selling product in category fashion_male_clothing (sold 14.0): \n",
      " ['e336c656869480e20d04ca9389b12167']\n",
      "best-selling product in category fashion_shoes (sold 15.0): \n",
      " ['ac5e164e2eda939ffa46593f90077f9a']\n",
      "best-selling product in category fashion_sport (sold 11.0): \n",
      " ['e8f7d2639ff8caa8b86e5973295898b7']\n",
      "best-selling product in category fashion_underwear_beach (sold 18.0): \n",
      " ['fa8485bc54eaad5b218cd8081c859568']\n",
      "best-selling product in category fixed_telephony (sold 36.0): \n",
      " ['5769ef0a239114ac3a854af00df129e4']\n",
      "best-selling product in category flowers (sold 10.0): \n",
      " ['7620a27f1d6747511f1c6f0ddb63c0ef']\n",
      "best-selling product in category food (sold 124.0): \n",
      " ['89321f94e35fc6d7903d36f74e351d40']\n",
      "best-selling product in category food_drink (sold 34.0): \n",
      " ['ec96b7b4e1401281edb9465d0d689cae']\n",
      "best-selling product in category furniture_bedroom (sold 16.0): \n",
      " ['4f18ca9862f511ecba98258b2194d061']\n",
      "best-selling product in category furniture_decor (sold 640.0): \n",
      " ['aca2eb7d00ea1a7b8ebd4e68314663af']\n",
      "best-selling product in category furniture_living_room (sold 68.0): \n",
      " ['58efb9b638561ce132216a9a612513e2']\n",
      "best-selling product in category furniture_mattress_and_upholstery (sold 22.0): \n",
      " ['726b4e18f00255e2e63491bcba3f60b8']\n",
      "best-selling product in category garden_tools (sold 793.0): \n",
      " ['422879e10f46682990de24d770e7f83d']\n",
      "best-selling product in category health_beauty (sold 300.0): \n",
      " ['154e7e31ebfa092203795c972e5804a6']\n",
      "best-selling product in category home_appliances (sold 38.0): \n",
      " ['be837f2e0152a208d4386f4126d5bd7c']\n",
      "best-selling product in category home_appliances_2 (sold 13.0): \n",
      " ['f27aff266ad97e75d4a24c893b2c311e']\n",
      "best-selling product in category home_comfort_2 (sold 35.0): \n",
      " ['ec5b3c8bb77ad22278f6e9d719a83de3']\n",
      "best-selling product in category home_confort (sold 198.0): \n",
      " ['35afc973633aaeb6b877ff57b2793310']\n",
      "best-selling product in category home_construction (sold 37.0): \n",
      " ['a39cc58c1b5926b6f9f378daa89f1315']\n",
      "best-selling product in category housewares (sold 209.0): \n",
      " ['42a2c92a0979a949ca4ea89ec5c7b934']\n",
      "best-selling product in category industry_commerce_and_business (sold 50.0): \n",
      " ['593236d0ff46b4299b4787fb8d43f7f0']\n",
      "best-selling product in category kitchen_dining_laundry_garden_furniture (sold 31.0): \n",
      " ['c075b8e131353552218860f1c421e4ef']\n",
      "best-selling product in category la_cuisine (sold 4.0): \n",
      " ['33900d427fa4bd3f509cdacda72e84a3']\n",
      "best-selling product in category luggage_accessories (sold 71.0): \n",
      " ['f71973c922ccaab05514a36a8bc741b8']\n",
      "best-selling product in category market_place (sold 33.0): \n",
      " ['cf1d8e226162a1d0ad61f29b7ed72d82']\n",
      "best-selling products in category music (sold 4.0): \n",
      " ['4befae07dba4384f6d8237ad1e7f8294' 'd655dc03de9b831ed22639631ab2958f']\n",
      "best-selling product in category musical_instruments (sold 23.0): \n",
      " ['738da8ddda2e593acfdc53c2d1520dfa']\n",
      "no product sold in category nan\n",
      "best-selling product in category office_furniture (sold 122.0): \n",
      " ['3eef0cb94ba82de806bb30ab743c7655']\n",
      "best-selling product in category party_supplies (sold 11.0): \n",
      " ['4a7056788ce9287c76ade358f2e2572a']\n",
      "best-selling product in category perfumery (sold 145.0): \n",
      " ['2028bf1b01cafb2d2b1901fca4083222']\n",
      "best-selling product in category pet_shop (sold 57.0): \n",
      " ['e1da6ab77f4859eb17950e5df1c0f815']\n",
      "best-selling products in category security_and_services (sold 1.0): \n",
      " ['6c7a0a349ad11817745e3ad58abd5c79' '8db75af9aed3315374db44d7860e25da']\n",
      "best-selling products in category signaling_and_security (sold 21.0): \n",
      " ['5d3b065e160c51e883cd7ef509a54176' 'bc3c6d2a621414f2e1df7a8a32a2828e']\n",
      "best-selling products in category small_appliances (sold 28.0): \n",
      " ['79366d6a24de9351b7ca6e3cf75a68ec' 'd2bea3c01e172037caa99b2d138f39d0']\n",
      "best-selling product in category small_appliances_home_oven_and_coffee (sold 19.0): \n",
      " ['f49e985b4cb2d0543890d6dd00077663']\n",
      "best-selling products in category sports_leisure (sold 114.0): \n",
      " ['c6336fa91fbd87c359e44f5dca5a90ed' 'd3c044bd42d84a79e3b0c42662806a48']\n",
      "best-selling product in category stationery (sold 89.0): \n",
      " ['fb55982be901439613a95940feefd9ee']\n",
      "best-selling product in category tablets_printing_image (sold 35.0): \n",
      " ['6bbe55cf8f85c87b6eebb775a53402f4']\n",
      "best-selling product in category telephony (sold 162.0): \n",
      " ['e7cc48a9daff5436f63d3aad9426f28b']\n",
      "best-selling product in category toys (sold 106.0): \n",
      " ['880be32f4db1d9f6e2bec38fb6ac23ab']\n",
      "best-selling product in category watches_gifts (sold 367.0): \n",
      " ['a62e25e09e05e6faf31d90c6ec1aa3d1']\n"
     ]
    }
   ],
   "source": [
    "data = dfs['orders'].merge(dfs['order_items'], on = 'order_id', how = 'left')\n",
    "data = data.merge(dfs['products'], on = 'product_id', how = 'left')\n",
    "\n",
    "if start_year !=0 and end_year !=0:\n",
    "    products_df = get_turnover(data, start_day, start_month, start_year, end_day, end_month, end_year)\n",
    "else:\n",
    "    products_df = data\n",
    "\n",
    "best_products = products_df.groupby('product_id')['order_item_id'].sum().reset_index()\n",
    "best_products.rename(columns={'order_item_id': 'sold_items'}, inplace=True)\n",
    "best_products = best_products.merge(dfs['products'], on = 'product_id', how = 'left')\n",
    "\n",
    "if isinstance(category, list):\n",
    "    for el in category:\n",
    "        prod_data = best_products.loc[best_products['product_category_name_english'] == el]\n",
    "        print_data(prod_data, el)\n",
    "elif isinstance(category, str):\n",
    "        prod_data = best_products.loc[best_products['product_category_name_english'] == category]\n",
    "        print_data(prod_data, category)\n",
    "else:\n",
    "    for el in all_categories:\n",
    "        prod_data = best_products.loc[best_products['product_category_name_english'] == el]\n",
    "        print_data(prod_data, el)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b344d84-9966-4818-8565-2364db803cb0",
   "metadata": {},
   "source": [
    "#### 4. the dependence of product weight on turnover and price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121d3ca-6b66-4f44-a7b3-f2633dd0fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "## select time period for products sale\n",
    "## if year parameters are 0 whole data frame will be used\n",
    "start_day = 1\n",
    "start_month = 1\n",
    "start_year = 0\n",
    "end_day = 1\n",
    "end_month = 1\n",
    "end_year = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07349ea9-0f81-4bf7-a532-1161bed6d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_4 = dfs['orders'].merge(dfs['order_items'], on = 'order_id', how = 'inner')\n",
    "\n",
    "if start_year !=0 and end_year !=0:\n",
    "    task_4 = get_turnover(turnover, start_day, start_month, start_year, end_day, end_month, end_year)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "task_4['tunover'] = task_4['price']*task4['order_item_id'] + task_4['freight_value']*task_4['order_item_id']\n",
    "task_4 = task_4.groupby('product_id').agg({'turnover': 'sum', 'price': 'mean', 'freight_value': 'mean'}).reset_index()\n",
    "task_4 = task_4.merge(dfs['products'], on = 'product_id', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30caa2f3-2a03-4172-b237-ae963550ab7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['sellers'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
