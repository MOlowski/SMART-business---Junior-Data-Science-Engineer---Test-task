{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ec162f-f3f0-4a94-b96a-a8171f29ebe3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMERS \n",
      "\n",
      "\n",
      "GEOLOCATION \n",
      "\n",
      "\n",
      "ORDER_ITEMS \n",
      "\n",
      "\n",
      "ORDER_PAYMENTS \n",
      "\n",
      "\n",
      "ORDER_REVIEWS \n",
      "\n",
      "\n",
      "ORDERS \n",
      "\n",
      "\n",
      "PRODUCT_CATEGORY_NAME_TRANSLATION \n",
      "\n",
      "\n",
      "PRODUCTS \n",
      "\n",
      "\n",
      "SELLERS \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = 'OneDrive_1_14/S_Data/'\n",
    "endpoint = '.csv'\n",
    "\n",
    "csvs = ['customers', \n",
    "        'geolocation', \n",
    "        'order_items', \n",
    "        'order_payments', \n",
    "        'order_reviews', \n",
    "        'orders', \n",
    "        'product_category_name_translation',\n",
    "        'products',\n",
    "        'sellers']\n",
    "dfs = {}\n",
    "\n",
    "for name in csvs:\n",
    "    print(name.upper(),'\\n\\n')\n",
    "    dfs[name] = pd.read_csv(path+name+endpoint)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91489b-2b80-4420-bf62-053a89358068",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb02869-1c32-4722-98aa-d4130e379cb9",
   "metadata": {},
   "source": [
    "### To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726d906-65f9-43f3-9d4d-980655bad458",
   "metadata": {},
   "source": [
    "#### get reviews in function same as other values in other df then merge dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f0014-3e35-419d-9ecb-667f4c46927a",
   "metadata": {},
   "source": [
    "##### (done) english name, \n",
    "##### (done) average delivery time, \n",
    "##### (done) average delivery time from last 14 days,\n",
    "##### (done) average product price,\n",
    "##### (done) actual product price,\n",
    "##### (done) sales from last 14 days, \n",
    "##### (done) total sale per seller from 14 days, \n",
    "##### reviews since products sale started, \n",
    "##### number of reviews added in 14 days, \n",
    "##### average fracht_val in past 14 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e535201-1b8a-4452-be09-d0236b0b2014",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e3480c-50ce-4fcb-a9eb-f8ce4a9ecd9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1. English name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2aef4bc-5d7a-4880-a556-593462e98448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_name_lenght</th>\n",
       "      <th>product_description_lenght</th>\n",
       "      <th>product_photos_qty</th>\n",
       "      <th>product_weight_g</th>\n",
       "      <th>product_length_cm</th>\n",
       "      <th>product_height_cm</th>\n",
       "      <th>product_width_cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>perfumaria</td>\n",
       "      <td>40.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>artes</td>\n",
       "      <td>44.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>esporte_lazer</td>\n",
       "      <td>46.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>bebes</td>\n",
       "      <td>27.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>utilidades_domesticas</td>\n",
       "      <td>37.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         product_id  product_category_name  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
       "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
       "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
       "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
       "\n",
       "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
       "0                 40.0                       287.0                 1.0   \n",
       "1                 44.0                       276.0                 1.0   \n",
       "2                 46.0                       250.0                 1.0   \n",
       "3                 27.0                       261.0                 1.0   \n",
       "4                 37.0                       402.0                 4.0   \n",
       "\n",
       "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
       "0             225.0               16.0               10.0              14.0  \n",
       "1            1000.0               30.0               18.0              20.0  \n",
       "2             154.0               18.0                9.0              15.0  \n",
       "3             371.0               26.0                4.0              26.0  \n",
       "4             625.0               20.0               17.0              13.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['products'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677b04e8-8c38-44b2-b628-138e4325688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_category_name</th>\n",
       "      <th>product_category_name_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beleza_saude</td>\n",
       "      <td>health_beauty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informatica_acessorios</td>\n",
       "      <td>computers_accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>automotivo</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cama_mesa_banho</td>\n",
       "      <td>bed_bath_table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moveis_decoracao</td>\n",
       "      <td>furniture_decor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_category_name product_category_name_english\n",
       "0            beleza_saude                 health_beauty\n",
       "1  informatica_acessorios         computers_accessories\n",
       "2              automotivo                          auto\n",
       "3         cama_mesa_banho                bed_bath_table\n",
       "4        moveis_decoracao               furniture_decor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['product_category_name_translation'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a2f321-178d-4f27-895d-30d91400e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get english category name\n",
    "\n",
    "dfs['products'] = dfs['products'].merge(dfs['product_category_name_translation'],\n",
    "                                        how = 'inner',\n",
    "                                        on = 'product_category_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290205e-d68b-40fa-8c34-e264ecc5baae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 2. Add missing delivery dates, get necessary date for subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daae76aa-382e-411f-9464-dbc20f777df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status order_purchase_timestamp    order_approved_at  \\\n",
       "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  \n",
       "0           2017-10-18 00:00:00  \n",
       "1           2018-08-13 00:00:00  \n",
       "2           2018-09-04 00:00:00  \n",
       "3           2017-12-15 00:00:00  \n",
       "4           2018-02-26 00:00:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['orders'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08b6726-f7f2-4d7b-9ec4-c669107c9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['delivered', 'invoiced', 'shipped', 'processing', 'unavailable',\n",
       "       'canceled', 'created', 'approved'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['orders']['order_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c3032f-7d7d-4b6a-99e9-db4683cc36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get only valid orders\n",
    "dfs['orders'] = dfs['orders'].loc[(dfs['orders']['order_status'] != 'canceled') & \n",
    "                                  (dfs['orders']['order_status'] != 'unavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "881e4e90-3dbf-4275-b722-a6530473d63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                            0\n",
      "customer_id                         0\n",
      "order_status                        0\n",
      "order_purchase_timestamp            0\n",
      "order_approved_at                  19\n",
      "order_delivered_carrier_date      624\n",
      "order_delivered_customer_date    1737\n",
      "order_estimated_delivery_date       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfs['orders'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd9fdce-65c0-4255-a32f-881a55bf7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                         object\n",
      "customer_id                      object\n",
      "order_status                     object\n",
      "order_purchase_timestamp         object\n",
      "order_approved_at                object\n",
      "order_delivered_carrier_date     object\n",
      "order_delivered_customer_date    object\n",
      "order_estimated_delivery_date    object\n",
      "dtype: object \n",
      " review_id                  object\n",
      "order_id                   object\n",
      "review_score                int64\n",
      "review_comment_title       object\n",
      "review_comment_message     object\n",
      "review_creation_date       object\n",
      "review_answer_timestamp    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dfs['orders'].dtypes,\n",
    "      '\\n', \n",
    "      dfs['order_reviews'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11670e78-0c47-43fe-9f35-150b3716e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge dataframes for product id, price, number of ordered items, reviews\n",
    "dfs['orders'] = dfs['order_items'].merge(dfs['orders'], on = 'order_id', how = 'right')\n",
    "dfs['orders'] = dfs['orders'].merge(dfs['order_reviews'], on='order_id', how ='left')\n",
    "dfs['orders'] = dfs['orders'].merge(dfs['products'], on = 'product_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d89049f-2c70-48c4-96e6-204fbbf70cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/m_9l75x14kz_37vfj8r34b2r0000gn/T/ipykernel_17079/1906626660.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dfs['orders']['order_delivered_customer_date'].ffill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dfs['orders']['order_purchase_timestamp'] = pd.to_datetime(dfs['orders']['order_purchase_timestamp'])\n",
    "dfs['orders']['order_delivered_customer_date'] = pd.to_datetime(dfs['orders']['order_delivered_customer_date'])\n",
    "dfs['orders']['review_creation_date'] = pd.to_datetime(dfs['orders']['review_creation_date'])\n",
    "\n",
    "## fill nan values after grouping by product id so values are more reliable\n",
    "dfs['orders'].sort_values(by='product_id', inplace=True)\n",
    "dfs['orders']['order_delivered_customer_date'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f020c555-1028-4bf7-b318-41aec7e6018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get order date, review date, delivery date and delivery time\n",
    "\n",
    "dfs['orders']['purchase_year'] = dfs['orders']['order_purchase_timestamp'].dt.year\n",
    "dfs['orders']['purchase_day'] = dfs['orders']['order_purchase_timestamp'].dt.dayofyear\n",
    "\n",
    "dfs['orders']['review_year'] = dfs['orders']['review_creation_date'].dt.year\n",
    "dfs['orders']['review_day'] = dfs['orders']['review_creation_date'].dt.dayofyear\n",
    "\n",
    "\n",
    "dfs['orders']['delivery_year'] = dfs['orders']['order_delivered_customer_date'].dt.year\n",
    "dfs['orders']['delivery_day'] = dfs['orders']['order_delivered_customer_date'].dt.dayofyear\n",
    "\n",
    "## calculate delivery time (check if delivery and purchase were made in same year)\n",
    "dfs['orders']['delivery_time'] = ((dfs['orders']['delivery_year'] - dfs['orders']['purchase_year'])*365 + \n",
    "                                 dfs['orders']['delivery_day'] - dfs['orders']['delivery_day'])\n",
    "\n",
    "## if delivery and purchase years were different check if purchase year was leap\n",
    "for index, row in dfs['orders'].iterrows():\n",
    "    if row['purchase_year'] != row['delivery_year']:\n",
    "        if row['purchase_year']%4 ==0 and row['purchase_year']%100 == 0 and row['purchase_year']%400 == 0:\n",
    "            dfs['orders'].at[index, 'delivery_time'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4fe5e-37b0-4e7a-afee-372fa8caecf6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818ac581-e992-41ad-b6cf-1f91f5526f20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## get data from 14 days\n",
    "def is_leap(year):\n",
    "    if year%4 == 0 and year%100 == 0 and year%400 == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "522bea02-2019-4078-b5ac-ea419568d6d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## get end of subset (check if it ends in following year)\n",
    "def get_end(year, day_s, sub_size):\n",
    "    \n",
    "    if is_leap(year):\n",
    "        if day_s > 366 - sub_size:\n",
    "            day_e = 366 - day_s\n",
    "            year_e = year + 1\n",
    "        else:\n",
    "            day_e = day_s + sub_size\n",
    "            year_e = year\n",
    "    else:\n",
    "        if day_s > 365 - sub_size:\n",
    "            day_e = 365 - day_s\n",
    "            year_e = year + 1\n",
    "        else:\n",
    "            day_e = day_s + sub_size\n",
    "            year_e = year\n",
    "    return day_s, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60785e56-cb8c-4d95-ae5b-257b9491d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(dfs, day_end, year_end, column_gb):\n",
    "    \n",
    "    ## income from product per order\n",
    "    dfs['orders']['incomes'] = dfs['orders']['order_item_id']*dfs['orders']['price']\n",
    "\n",
    "    ## orders till end date\n",
    "    orders_bef = dfs['orders'].loc[(dfs['orders']['purchase_year'] < year_end) |\n",
    "                                   ((dfs['orders']['purchase_year'] == year_end) &\n",
    "                                    (dfs['orders']['purchase_day'] < day_end))]\n",
    "    ## df with orders before end day\n",
    "    df_bef = orders_bef.groupby(column_gb).agg({'delivery_time': 'mean', \n",
    "                                                                      'price': 'mean', \n",
    "                                                                      'order_item_id': 'sum', \n",
    "                                                                      'incomes': 'sum',\n",
    "                                                                      'freight_value': 'mean'}).reset_index()    \n",
    "    ## df with orders per seller before end day \n",
    "    df_bef_per_seller = orders_bef.groupby([column_gb, 'seller_id']).agg({'delivery_time': 'mean', \n",
    "                                                                                                'price': 'mean', \n",
    "                                                                                                'order_item_id': 'sum',\n",
    "                                                                                                'incomes': 'sum',\n",
    "                                                                                                'freight_value': 'mean'}).reset_index()\n",
    "    ## reviews since sale began\n",
    "    review_bef = dfs['orders'].loc[(dfs['orders']['review_year'] < year_end) |\n",
    "                                   ((dfs['orders']['review_year'] == year_end) &\n",
    "                                    (dfs['orders']['review_day'] < day_end))]\n",
    "    \n",
    "    ## df with mean reviews score for each product category since it sales began\n",
    "    df_bef_reviews = review_bef.groupby(column_gb)['review_score'].mean().reset_index()\n",
    "\n",
    "    ## merging dataframes to get proper information about product\n",
    "    df_before_start_day = df_bef.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_before_start_day.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "    \n",
    "    ## merging dataframes with collected informations for each seller\n",
    "    df_before_start_day_per_seller = df_bef_per_seller.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_before_start_day_per_seller.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "\n",
    "## at the end we have 2 dataframes: \n",
    "## 1st with product information since it sales began to start day\n",
    "## 2nd with product information same as in 1st one but for each seller\n",
    "    return(df_before_start_day, df_before_start_day_per_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8d3653-bcc4-4384-88f2-dc20b4c6b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_data(dfs, year, day_s, sub_size, column_gb):\n",
    "    \n",
    "    ##calculate end of subset\n",
    "    day_e, year_e = get_end(year, day_s, sub_size)\n",
    "\n",
    "    ## income from product per order\n",
    "    dfs['orders']['incomes'] = dfs['orders']['order_item_id']*dfs['orders']['price']\n",
    "    \n",
    "    ## orders from start date to end date\n",
    "    if year == year_e:\n",
    "        orders_act = dfs['orders'].loc[(dfs['orders']['purchase_year'] == year) & \n",
    "                                       (dfs['orders']['purchase_day'] >= day_s) & \n",
    "                                       (dfs['orders']['purchase_day'] <= day_e)]\n",
    "    else:\n",
    "        orders_act = dfs['orders'].loc[((dfs['orders']['purchase_year'] == year) & \n",
    "                                        (dfs['orders']['purchase_day'] >= day_s)) |\n",
    "                                       ((dfs['orders']['purchase_year'] == year_e) & \n",
    "                                        (dfs['orders']['purchase_day'] <= day_e))]\n",
    "                                        \n",
    "## each dataframe consists \n",
    "##    mean values: delivery time, price and freight value\n",
    "##    sum values: incomes and number of ordered items\n",
    "\n",
    "    ## df with orders from start date to end date\n",
    "    df_act = orders_act.groupby(column_gb).agg({'delivery_time': 'mean', \n",
    "                                                   'price': 'mean', \n",
    "                                                   'order_item_id': 'sum', \n",
    "                                                   'incomes': 'sum',\n",
    "                                                   'freight_value': 'mean'}).reset_index()\n",
    "                                \n",
    "## same information collected for each seller\n",
    "\n",
    "    ## df with orders from start date to end date\n",
    "    df_act_per_seller = orders_act.groupby([column_gb, 'seller_id']).agg({'delivery_time': 'mean', \n",
    "                                                                             'price': 'mean', \n",
    "                                                                             'order_item_id': 'sum',\n",
    "                                                                             'incomes': 'sum',\n",
    "                                                                             'freight_value': 'mean'}).reset_index()\n",
    "\n",
    "    ## reviews added between start and end date \n",
    "    if year == year_e:\n",
    "        review_act = dfs['orders'].loc[(dfs['orders']['review_year'] == year) & \n",
    "                                       (dfs['orders']['review_day'] >= day_s) & \n",
    "                                       (dfs['orders']['review_day'] <= day_e)]\n",
    "    else:\n",
    "        review_act = dfs['orders'].loc[((dfs['orders']['review_year'] == year) & \n",
    "                                        (dfs['orders']['review_day'] >= day_s)) |\n",
    "                                       ((dfs['orders']['review_year'] == year_e) & \n",
    "                                        (dfs['orders']['review_day'] <= day_e))]\n",
    "\n",
    "    ## df with mean reviews score value in time period from start to end date for each product \n",
    "    df_act_reviews = review_act.groupby(column_gb)['review_score'].mean().reset_index()\n",
    "\n",
    "## merging dataframes to get proper information about product\n",
    "    df_actual = df_act.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_actual.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                              'price': 'avg_price',\n",
    "                              'order_item_id' : 'number_of_sold_items',\n",
    "                              'freight_value': 'avg_freight_val',\n",
    "                              'review_score': 'avg_review_score'},\n",
    "                     inplace = True)                     \n",
    "\n",
    "## merging dataframes with collected informations for each seller\n",
    "    df_actual_per_seller = df_act_per_seller.merge(df_bef_reviews, on = column_gb, how = 'left')\n",
    "    df_actual_per_seller.rename(columns={'delivery_time': 'avg_delivery_time', \n",
    "                                        'price': 'avg_price',\n",
    "                                        'order_item_id' : 'number_of_sold_items',\n",
    "                                        'freight_value': 'avg_freight_val',\n",
    "                                        'review_score': 'avg_review_score'},\n",
    "                               inplace = True)\n",
    "\n",
    "## at the end we have 2 dataframes: \n",
    "## 1st with product information from start date to end date\n",
    "## 2nd with product information same as in 1st one but for each seller\n",
    "    return(df_actual, df_actual_per_seller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e4de-733b-4752-9627-b60e9f912322",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate period of time for historical data\n",
    "def period(day, year, year_start, day_start):\n",
    "    if year == year_start:\n",
    "        return day - day_start\n",
    "    elif year - year_start == 1:\n",
    "        if is_leap(year_start):\n",
    "            return day + 366 - day_start\n",
    "        else:\n",
    "            return day + 365 - day_start\n",
    "    else:\n",
    "        if is_leap(year_start):\n",
    "            days = 366 - day_start\n",
    "        else:\n",
    "            days = 365 - day_start\n",
    "        for i in range(year-year_start-1):\n",
    "            if is_leap(year_start+i+1):\n",
    "                days+=366\n",
    "            else:\n",
    "                days+=365\n",
    "        return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb061a-30a4-421b-a0b3-e144a6cbd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates_subset(df, day_s, year_s, sub_size):\n",
    "    day_e, year_e = get_end(year, day_s, sub_size)\n",
    "    df['start_day'] = day_start\n",
    "    df['start_year'] = year_start\n",
    "    df['time_period'] = sub_size\n",
    "    df['end_day'] = day_e\n",
    "    df['end_year'] = year_e\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b7916-97fc-4f23-a482-a8218515650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates_historical(df, day_start, year_start, day_end, year_end):\n",
    "    df['start_day'] = day_start\n",
    "    df['start_year'] = year_start\n",
    "    df['time_period'] = period(day_end, year_end)\n",
    "    df['end_day'] = day_end\n",
    "    df['end_year'] = year_end\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb0d374-cb6f-4d43-ae0a-003d95266bdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [product_category, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                  product_category  avg_delivery_time   avg_price  \\\n",
       " 0                 air_conditioning         146.000000  170.709000   \n",
       " 1                            audio           0.000000   78.495000   \n",
       " 2                             auto          81.111111  156.472222   \n",
       " 3                             baby           0.000000  124.651818   \n",
       " 4                   bed_bath_table           0.000000   59.873750   \n",
       " 5           books_general_interest         365.000000  119.500000   \n",
       " 6                  books_technical         365.000000  267.000000   \n",
       " 7            computers_accessories         191.190476   66.634286   \n",
       " 8                   consoles_games          73.000000  388.226000   \n",
       " 9                       cool_stuff           0.000000  149.442857   \n",
       " 10             diapers_and_hygiene           0.000000  134.900000   \n",
       " 11                     electronics           0.000000  107.990000   \n",
       " 12          fashio_female_clothing           0.000000   54.900000   \n",
       " 13        fashion_bags_accessories           0.000000   46.662500   \n",
       " 14           fashion_male_clothing           0.000000   24.900000   \n",
       " 15                   fashion_shoes           0.000000   29.990000   \n",
       " 16                 fixed_telephony           0.000000  140.976000   \n",
       " 17                            food           0.000000   79.900000   \n",
       " 18                 furniture_decor          29.594595   86.587297   \n",
       " 19                    garden_tools           0.000000  271.976000   \n",
       " 20                   health_beauty          44.693878   92.848776   \n",
       " 21                      housewares           0.000000  107.255833   \n",
       " 22  industry_commerce_and_business           0.000000   89.900000   \n",
       " 23                    market_place         112.307692  100.476154   \n",
       " 24                office_furniture           0.000000  216.813333   \n",
       " 25                       perfumery           0.000000  166.520690   \n",
       " 26                        pet_shop           0.000000  172.420000   \n",
       " 27                  sports_leisure           0.000000  118.361765   \n",
       " 28                       telephony          40.555556   28.908889   \n",
       " 29                            toys           0.000000  171.104167   \n",
       " 30                   watches_gifts         146.000000  672.048000   \n",
       " \n",
       "     number_of_sold_items  incomes  avg_freight_val  avg_review_score  \n",
       " 0                   18.0  2935.29        19.782000          3.800000  \n",
       " 1                    2.0   156.99        13.020000          5.000000  \n",
       " 2                    9.0  1408.25        38.245556          2.857143  \n",
       " 3                   13.0  1510.97        13.307273          4.090909  \n",
       " 4                   16.0   757.77        15.948750          3.375000  \n",
       " 5                    1.0   119.50        25.040000               NaN  \n",
       " 6                    1.0   267.00        32.840000          1.000000  \n",
       " 7                   27.0  1627.32        16.227143          2.761905  \n",
       " 8                   10.0  3882.26        20.716000          3.400000  \n",
       " 9                    7.0  1046.10        27.254286          4.142857  \n",
       " 10                   1.0   134.90        16.090000          5.000000  \n",
       " 11                   1.0   107.99        11.800000          5.000000  \n",
       " 12                   1.0    54.90        14.730000          5.000000  \n",
       " 13                   9.0   398.20        16.210000          3.500000  \n",
       " 14                   1.0    24.90        10.960000          1.000000  \n",
       " 15                   1.0    29.99        10.960000          5.000000  \n",
       " 16                   5.0   704.88        13.914000          4.000000  \n",
       " 17                   1.0    79.90        16.330000          5.000000  \n",
       " 18                 112.0  7983.64        18.675000          3.575342  \n",
       " 19                   5.0  1359.88        21.062000          4.200000  \n",
       " 20                  56.0  4914.25        18.424694          3.208333  \n",
       " 21                  16.0  1816.67        21.289167          3.083333  \n",
       " 22                   5.0   449.50        18.490000          4.250000  \n",
       " 23                  29.0  2652.59        20.999231          4.538462  \n",
       " 24                   6.0  1300.88        47.778333          1.600000  \n",
       " 25                  33.0  5213.70        16.762069          4.310345  \n",
       " 26                   4.0   689.68        21.545000          4.250000  \n",
       " 27                  17.0  2012.15        28.153529          4.250000  \n",
       " 28                  10.0   300.08        13.512222          4.111111  \n",
       " 29                  26.0  4421.39        20.209583          3.666667  \n",
       " 30                   5.0  3360.24        21.560000          4.750000  ,\n",
       " Empty DataFrame\n",
       " Columns: [product_category, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
       " Index: [],\n",
       "      product_category                         seller_id  avg_delivery_time  \\\n",
       " 0    air_conditioning  c7dcd301ecfe5ab7f778ac172cf74be7           0.000000   \n",
       " 1    air_conditioning  ed859002ad59dbf8cf3602696a6c3000         162.222222   \n",
       " 2               audio  5f0057b677eb963672bf05dfa3f16c34           0.000000   \n",
       " 3                auto  63b9ae557efed31d1f7687917d248a8d           0.000000   \n",
       " 4                auto  6cf476a4ca74498db55cbccdaa9dcfb6           0.000000   \n",
       " ..                ...                               ...                ...   \n",
       " 161              toys  f5f2ab9bdb6b30c14c61be68c5ed37da           0.000000   \n",
       " 162              toys  fa40cc5b934574b62717c68f3d678b6d           0.000000   \n",
       " 163     watches_gifts  4d600e08ecbe08258c79e536c5a42fee         243.333333   \n",
       " 164     watches_gifts  522620dcb18a6b31cd7bdf73665113a9           0.000000   \n",
       " 165     watches_gifts  7e93a43ef30c4f03f38b393420bc753a           0.000000   \n",
       " \n",
       "        avg_price  number_of_sold_items  incomes  avg_freight_val  \\\n",
       " 0     299.990000                   1.0   299.99        19.010000   \n",
       " 1     156.344444                  17.0  2635.30        19.867778   \n",
       " 2      78.495000                   2.0   156.99        13.020000   \n",
       " 3      10.000000                   1.0    10.00        14.520000   \n",
       " 4     499.990000                   1.0   499.99        94.470000   \n",
       " ..           ...                   ...      ...              ...   \n",
       " 161    71.945000                   2.0   143.89        20.185000   \n",
       " 162    49.900000                   1.0    49.90        24.840000   \n",
       " 163   643.780000                   3.0  1931.34        22.563333   \n",
       " 164    29.900000                   1.0    29.90        15.560000   \n",
       " 165  1399.000000                   1.0  1399.00        24.550000   \n",
       " \n",
       "      avg_review_score  \n",
       " 0            3.800000  \n",
       " 1            3.800000  \n",
       " 2            5.000000  \n",
       " 3            2.857143  \n",
       " 4            2.857143  \n",
       " ..                ...  \n",
       " 161          3.666667  \n",
       " 162          3.666667  \n",
       " 163          4.750000  \n",
       " 164          4.750000  \n",
       " 165          4.750000  \n",
       " \n",
       " [166 rows x 8 columns],\n",
       " Empty DataFrame\n",
       " Columns: [product_category, seller_id, avg_delivery_time, avg_price, number_of_sold_items, incomes, avg_freight_val, avg_review_score]\n",
       " Index: [])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_14(dfs, year_start, day_start+100, subset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73562ffb-518e-482c-8ec4-a7bf6e9bffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "year_start = dfs['orders'].sort_values(by='purchase_year')['purchase_year'].values[0]\n",
    "day_start =  dfs['orders'].sort_values(by=['purchase_year', 'purchase_day'])['purchase_day'].values[0]\n",
    "\n",
    "year_end =  dfs['orders'].sort_values(by='purchase_year', ascending = False)['purchase_year'].values[0]\n",
    "day_end =  dfs['orders'].sort_values(by=['purchase_year', 'purchase_day'], \n",
    "                                     ascending = [False, False])['purchase_day'].values[0]\n",
    "if day_end >= 7:\n",
    "    day_end -= 7\n",
    "else:\n",
    "    year_end -= 1\n",
    "    day_end = 365 + day_end - 7\n",
    "    if is_leap(year_end):\n",
    "        day_end += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "offset = 0 # after how many subset collected  you want to start collecting historical data (from start day there wont be much data)\n",
    "subset_size = 14\n",
    "loop = 0\n",
    "start = True\n",
    "is_product_new = False\n",
    "\n",
    "\n",
    "if is_product_new:\n",
    "    column_groupby = 'product_id'\n",
    "else:\n",
    "    column_groupby = 'product_category_name_english'\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data_per_seller = pd.DataFrame()\n",
    "\n",
    "## go through all years and days, start parameter let start from proper day\n",
    "for year in range(year_start, year_end +1):\n",
    "    for day in range(0, 365):\n",
    "        loop += 1\n",
    "        if start:\n",
    "            day = day_start\n",
    "            start = False\n",
    "            pass\n",
    "        else:\n",
    "            if (day >= day_end)&(year>=year_end):\n",
    "                break\n",
    "            else:\n",
    "                actual, actual_per_seller = get_subset_data(dfs, year, day, subset_size, columns_groupby)\n",
    "                actual = add_dates_subset(actual, day_start, year_start, subset_size)\n",
    "                actual_per_seller = add_dates_subset(before_per_seller, day_start, year_start, subset_size)\n",
    "                if loop == 1:\n",
    "                    data = actual\n",
    "                    data_per_seller = actual_per_seller\n",
    "                else:\n",
    "                    data = pd.concat([data, actual], ignore_index=True)\n",
    "                    data_per_seller = pd.concat([data_per_seller, actual_per_seller], ignore_index=True)\n",
    "                day = day + subset_size\n",
    "                \n",
    "historical, historical_per_seller =  get_historical_data(dfs, day_end, year_end, columns_groupby)\n",
    "historical = add_dates_historical(historical, day_start, year_start, day_end, year_end)\n",
    "historical_per_seller = add_dates_historical(historical_per_seller, day_start, year_start, day_end, year_end)\n",
    "data = pd.concat([data, historical], ignore_index=True)\n",
    "data_per_seller = pd.concat([data_per_seller, historical_per_seller], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa362c-e2b1-400e-ae0c-4b842e6925cd",
   "metadata": {},
   "source": [
    "### TIME FOR TRAIN AND TEST \n",
    "### ALSO CHECK IF NEW PRODUCT IF YES FIND SIMILIAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec304775-436d-443b-ae89-bde03fb4a582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
